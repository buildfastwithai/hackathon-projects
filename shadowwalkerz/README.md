## Team Name : Shadow Walkerz
# Project : Perception
## ðŸŒŸ What is PERCEPTION?

*PERCEPTION* is a revolutionary tool that leverages *Generative AI* to convert static text-based content (from books, PDFs, and more) into *context-aware, dynamic videos*. By providing fresh visual perspectives with each video generation, it transforms the way we learn, making it more engaging, enjoyable, and effective for all types of learners.

With PERCEPTION, you can say goodbye to monotonous reading and embrace a multi-sensory learning experience. ðŸŽ¬ðŸ“š


*How can we enhance engagement and retention in traditional text-based learning?*

Many learners struggle with staying motivated while reading dense, text-heavy materials. PERCEPTION addresses this by transforming static paragraphs into immersive videos, catering to different learning styles and improving retention.

## Backend Setup
- In Backend Folder You need to download the dataset of images Collection
- Backend -> dataset -> english set in this format
- link dataset - https://drive.proton.me/urls/EYC8KE7S84#FmDZysBlWdi5
- AFTER

# Installation Backend
-- "pip install -r requirements.txt"
- if any error occur related to community and command error text file available in folder

# Run Background Command
- "python app.py"

![image](https://github.com/user-attachments/assets/16668054-41e1-4200-9cc5-b5e324a56642)


## install the app 
# First its neccessary proper to set up flutter

- download flutter and set up
# commands
-- "flutter clean"

-- "flutter pub get"


# api setup  
- In constant.dart file : "http://.... app.py paste"

# Run the app 
-- "flutter run" command

# Build the apk File
- firstly project name change to "preception" because during building apk its finds the proper path
# commands

-- "flutter build apk"
---

## ðŸ’» How It Works

1. *Text Input*: Users can input text from any source (books, PDFs, articles).
2. *Context Analysis*: The text is analyzed using NLP to understand its context, tone, and key themes.
3. *Video Generation*: Using MoviePy, relevant visuals and animations are generated to reflect the textâ€™s meaning.
4. *Text-to-Speech*: The text is narrated using gTTS/pyttsx3, providing an immersive audio experience.
5. *Final Output*: The generated video, complete with visuals and narration, is delivered to the user.

---

## ðŸš€ Key Features
- *AI-Powered Video Generation*: Converts text into dynamic, visually engaging videos.
- *Text-to-Speech Narration*: Provides audio narration synchronized with visual content for an immersive learning experience.
- *Multi-Sensory Engagement*: Engages learners through visual, auditory, and contextual formats.
- *Supports Diverse Learning Styles*: Tailored content for visual, auditory, and kinesthetic learners.
- *Fresh Perspectives*: Each video generation offers a new interpretation of the content, keeping learning fresh and exciting.

---

## ðŸ”§ Technologies Used
- *Python*: Backend processing and logic
- *Flask*: Lightweight framework for web deployment
- *MoviePy*: Video generation and editing
- *gTTS* & *pyttsx3*: Text-to-speech libraries
- *Natural Language Processing (NLP)*: For contextual analysis of text

---



